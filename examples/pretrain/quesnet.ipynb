{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutingning/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import codecs\n",
    "from EduNLP.Pretrain import QuesNetTokenizer, pretrain_QuesNet\n",
    "from EduNLP.Vector import T2V\n",
    "from EduNLP.I2V import QuesNet, get_pretrained_i2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练自己的QuesNet模型\n",
    "## 1. 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置你的数据路径和输出路径\n",
    "BASE_DIR = \"/your/own/base/path\"\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/static/test_data\"\n",
    "output_dir = f\"{BASE_DIR}/examples/test_model/quesnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data():\n",
    "    _data = []\n",
    "    data_path = os.path.join(data_dir, \"quesnet_data.json\")\n",
    "    with codecs.open(data_path, encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            _data.append(json.loads(line))\n",
    "    return _data\n",
    "\n",
    "raw_data = raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save words(3): 79/79 = 1.0000                  with frequency 10416/10416=1.0000\n",
      "save meta information know_name: 12\n",
      "vocab_size:  82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = QuesNetTokenizer(meta=['know_name'], max_length=50,\n",
    "                             img_dir=os.path.join(data_dir, \"quesnet_img\"))\n",
    "\n",
    "# 设置词表\n",
    "tokenizer.set_vocab(raw_data, key=lambda x: x['ques_content'], trim_min_count=3, silent=False)\n",
    "\n",
    "print(\"vocab_size: \", tokenizer.vocab_size)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存tokenizer\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练QuesNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "335it [00:01, 170.71it/s]                         \n",
      "EduNLP, INFO QuesNet Word Embedding loaded\n",
      "0it [00:00, ?it/s]EduNLP, INFO [Epoch0][Batch0]Training image Embedding layer, loss:0.33119991421699524\n",
      "6it [00:00, 58.39it/s]EduNLP, INFO [Epoch0][Batch10]Training image Embedding layer, loss:0.2898443043231964\n",
      "11it [00:00, 64.49it/s]\n",
      "EduNLP, INFO QuesNet Image Embedding loaded\n",
      "0it [00:00, ?it/s]/Users/yutingning/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/EduNLP/Pretrain/quesNet_vec.py:582: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.data[idx])\n",
      "EduNLP, INFO [Epoch0][Batch0]Training meta Embedding layer, loss:0.6941184401512146\n",
      "EduNLP, INFO [Epoch0][Batch10]Training meta Embedding layer, loss:0.46297648549079895\n",
      "EduNLP, INFO [Epoch0][Batch20]Training meta Embedding layer, loss:0.3208733797073364\n",
      "21it [00:00, 450.85it/s]\n",
      "EduNLP, INFO QuesNet Meta Embedding loaded\n",
      "EduNLP, INFO QuesNet Word, Image and Meta Embeddings training is done\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]EduNLP, INFO 0.0---loss: 12.606732368469238\n",
      " 48%|████▊     | 10/21 [00:14<00:15,  1.40s/it]EduNLP, INFO 0.10---loss: 9.26207160949707\n",
      " 95%|█████████▌| 20/21 [00:27<00:01,  1.13s/it]EduNLP, INFO 0.20---loss: 8.061391830444336\n",
      "100%|██████████| 21/21 [00:28<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# 自定义训练参数\n",
    "train_params = {\n",
    "    'feat_size': 256,\n",
    "    'save_every': 10,\n",
    "    'emb_size': 256,\n",
    "    'batch_size': 16\n",
    "}\n",
    "pretrain_QuesNet(os.path.join(data_dir, 'quesnet_data.json'),\n",
    "                 output_dir, tokenizer, True, train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 使用训练好的QuesNet Tokenzier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取保存的tokenizer\n",
    "tokenizer = QuesNetTokenizer.from_pretrained(output_dir,\n",
    "                                             img_dir=os.path.join(data_dir, \"quesnet_img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['埃及', '胡夫', '金字塔', '古代', '世界', '建筑', '奇迹', '形状', '视为', '正四', '棱锥', '以该', '四', '棱锥', '高为', '边长', '正方形', '面积', '等于', '四', '棱锥', '侧面', '三角形', '面积', '侧面', '三角形', '底边', '高', '底面', '正方形', '边长', '比值', \\FigureID{73d66b18-33a9-11ec-a11a-98fa9b625adb}]\n",
      "\n",
      "[['埃及', '胡夫', '金字塔', '古代', '世界', '建筑', '奇迹', '形状', '视为', '正四', '棱锥', '以该', '四', '棱锥', '高为', '边长', '正方形', '面积', '等于', '四', '棱锥', '侧面', '三角形', '面积', '侧面', '三角形', '底边', '高', '底面', '正方形', '边长', '比值', \\FigureID{73d66b18-33a9-11ec-a11a-98fa9b625adb}], ['某校', '课外', '学习', '小组', '研究', '作物', '发芽率', 'y', '温度', 'x', '单位', '^', '{', '\\\\circ', '}', '\\\\mathrm', '{', 'C', '}', '关系', '20', '温度', '条件', '种子', '发芽', '实验', '实验', '数据', '\\\\left', '(', 'x', '_', '{', 'i', '}', ',', 'y', '_', '{', 'i', '}', '\\\\right', ')', '(', 'i', '=', '1', ',', '2', ','], ['设', '函数', 'f', '(', 'x', ')', '=', '\\\\cos', '\\\\left', '(', '\\\\omega', 'x', '+', '\\\\frac', '{', '\\\\pi', '}', '{', '6', '}', '\\\\right', ')', '[', '-', '\\\\pi', ',', '\\\\pi', ']', '图像', '图', \\FigureID{000004d6-0479-11ec-829b-797d5eb43535}, 'f', '(', 'x', ')', '最小', '周期'], ['执行', '右面', '程序框图', \\FigureID{000004d6-0479-11ec-829b-797d5eb43535}, '输出', 'n', '='], ['埃及', '胡夫', '金字塔', '古代', '世界', '建筑', '奇迹', '形状', '视为', '正四', '棱锥', '以该', '四', '棱锥', '高为', '边长', '正方形', '面积', '等于', '四', '棱锥', '侧面', '三角形', '面积', '侧面', '三角形', '底边', '高', '底面', '正方形', '边长', '比值', \\FigureID{73d66b18-33a9-11ec-a11a-98fa9b625adb}]]\n",
      "\n",
      "{'content_idx': [49, 72, 78, 43, 34, 56, 50, 57, 73, 64, 63, 35, 46, 63, 81, 77, 65, 79, 71, 46, 63, 37, 33, 79, 37, 33, 54, 80, 55, 65, 77, 66, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'meta_idx': {'know_name': [8, 7, 5]}, 'content': ['埃及', '胡夫', '金字塔', '古代', '世界', '建筑', '奇迹', '形状', '视为', '正四', '棱锥', '以该', '四', '棱锥', '高为', '边长', '正方形', '面积', '等于', '四', '棱锥', '侧面', '三角形', '面积', '侧面', '三角形', '底边', '高', '底面', '正方形', '边长', '比值', \\FigureID{73d66b18-33a9-11ec-a11a-98fa9b625adb}], 'meta': {'know_name': ['立体几何', '空间几何体', '棱柱的结构特征']}}\n",
      "\n",
      "{'content_idx': [[49, 72, 78, 43, 34, 56, 50, 57, 73, 64, 63, 35, 46, 63, 81, 77, 65, 79, 71, 46, 63, 37, 33, 79, 37, 33, 54, 80, 55, 65, 77, 66, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [62, 75, 51, 53, 68, 36, 42, 30, 67, 29, 40, 24, 31, 15, 32, 19, 31, 13, 32, 38, 10, 67, 61, 69, 41, 52, 52, 59, 18, 3, 29, 25, 31, 27, 32, 6, 30, 25, 31, 27, 32, 22, 4, 3, 27, 12, 8, 6, 9, 6], [74, 39, 26, 3, 29, 4, 12, 16, 18, 3, 20, 29, 5, 17, 31, 21, 32, 31, 11, 32, 22, 4, 14, 7, 21, 6, 21, 23, 48, 47, <PIL.Image.Image image mode=L size=56x56 at 0x7FC9ED1F52D0>, 26, 3, 29, 4, 60, 45, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]], 'meta_idx': [{'know_name': [8, 7, 5]}, {'know_name': [4, 11, 3]}, {'know_name': [1, 1, 2]}]}\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "# 可以处理单个题目\n",
    "print(tokenizer.tokenize(raw_data[0], key=lambda x: x['ques_content']))\n",
    "print()\n",
    "# 也可以处理题目列表\n",
    "print(tokenizer.tokenize(raw_data[:5], key=lambda x: x['ques_content']))\n",
    "\n",
    "print()\n",
    "\n",
    "# 将token转换为index\n",
    "print(tokenizer(raw_data[0], key=lambda x: x['ques_content'], return_text=True, padding=True))\n",
    "print()\n",
    "print(tokenizer(raw_data[:3], key=lambda x: x['ques_content'], padding=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 使用训练好的QuesNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "    'tokenizer_config_dir': output_dir,\n",
    "}\n",
    "i2v = QuesNet('quesnet', 'quesnet', output_dir,\n",
    "              tokenizer_kwargs=tokenizer_kwargs, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 34, 256])\n",
      "\n",
      "torch.Size([1, 34, 256])\n",
      "torch.Size([1, 256])\n",
      "\n",
      "torch.Size([2, 51, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 获得单个题目的表征\n",
    "i_vec, t_vec = i2v(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "print(i_vec.shape)\n",
    "print(t_vec.shape)\n",
    "print()\n",
    "\n",
    "# 也可以分别获得题目表征和各个token的表征\n",
    "t_vec = i2v.infer_token_vector(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "i_vec = i2v.infer_item_vector(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "print(t_vec.shape)\n",
    "print(i_vec.shape)\n",
    "print()\n",
    "\n",
    "# 获得题目列表的表征\n",
    "t_vec = i2v.infer_token_vector(raw_data[:2], key=lambda x: x[\"ques_content\"])\n",
    "i_vec = i2v.infer_item_vector(raw_data[:2], key=lambda x: x[\"ques_content\"])\n",
    "print(t_vec.shape)\n",
    "print(i_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 使用EduNLP中公开的预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EduNLP, INFO model_path: /Users/yutingning/Desktop/Project/LUNA/EduNLP/examples/test_model/data/quesnet/quesnet_test/quesnet_test\n",
      "EduNLP, INFO Use pretrained t2v model quesnet_test\n",
      "downloader, INFO http://base.ustc.edu.cn/data/model_zoo/modelhub/quesnet_pub_256/1/quesnet_test.zip is saved as /Users/yutingning/Desktop/Project/LUNA/EduNLP/examples/test_model/data/quesnet/quesnet_test/quesnet_test.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/yutingning/Desktop/Project/LUNA/EduNLP/examples/test_model/data/quesnet/quesnet_test/quesnet_test.zip 100.00%: 13.9MB | 13.9MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO /Users/yutingning/Desktop/Project/LUNA/EduNLP/examples/test_model/data/quesnet/quesnet_test/quesnet_test.zip is unzip to /Users/yutingning/Desktop/Project/LUNA/EduNLP/examples/test_model/data/quesnet/quesnet_test/quesnet_test\n"
     ]
    }
   ],
   "source": [
    "# 获取公开的预训练模型\n",
    "pretrained_dir = f\"{BASE_DIR}/examples/test_model/quesnet/quesnet_test\"\n",
    "i2v = get_pretrained_i2v(\"quesnet_test\", model_dir=pretrained_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 34, 256])\n",
      "\n",
      "torch.Size([1, 34, 256])\n",
      "torch.Size([1, 256])\n",
      "\n",
      "torch.Size([2, 51, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# 用法和4.2中相同\n",
    "\n",
    "# 获得单个题目的表征\n",
    "i_vec, t_vec = i2v(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "print(i_vec.shape)\n",
    "print(t_vec.shape)\n",
    "print()\n",
    "\n",
    "# 也可以分别获得题目表征和各个token的表征\n",
    "t_vec = i2v.infer_token_vector(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "i_vec = i2v.infer_item_vector(raw_data[0], key=lambda x: x[\"ques_content\"])\n",
    "print(t_vec.shape)\n",
    "print(i_vec.shape)\n",
    "print()\n",
    "\n",
    "# 获得题目列表的表征\n",
    "t_vec = i2v.infer_token_vector(raw_data[:2], key=lambda x: x[\"ques_content\"])\n",
    "i_vec = i2v.infer_item_vector(raw_data[:2], key=lambda x: x[\"ques_content\"])\n",
    "print(t_vec.shape)\n",
    "print(i_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f2a26ee7085c593a24cc14fd3813042ae0d8924be52d70a5ae56ba8d7e7914"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用QuesNet向量化容器\n",
    "## 导入功能块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MySoftwares\\Anaconda\\envs\\data\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from EduNLP.Pretrain import DisenQTokenizer\n",
    "from EduNLP.Vector import T2V, DisenQModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../..\"\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/static/test_data\"\n",
    "output_dir = f\"{BASE_DIR}/examples/test_model/data/disenq\"\n",
    "\n",
    "# 对题目文本进行令牌化\n",
    "items = [\n",
    "    \"有 公 式 $\\\\FormFigureID{wrong1?}$ ，如 图 $\\\\FigureID{088f15ea-xxx}$\",\n",
    "    \"已知 圆 $x^{2}+y^{2}-6 x=0$ ，过 点 (1,2) 的 直 线 被 该 圆 所 截 得 的 弦 的 长度 的 最小 值 为\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 令牌化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content_idx': tensor([[3548,    1, 2752,    1,    1, 1821,    1]]), 'content_len': tensor([7])}\n",
      "\n",
      "{'content_idx': tensor([[3548,    1, 2752,    1,    1, 1821,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2],\n",
      "        [2568, 1829,    1,    1,    1, 4364,    1, 4737, 4772, 5196, 5699, 5813,\n",
      "         1829, 2938, 2921, 2817, 4737,    1, 4737, 6428, 4737, 3527,  855,  463]]), 'content_len': tensor([ 7, 24])}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DisenQTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# 可以对单个题目进行令牌化\n",
    "print(tokenizer(items[0]))\n",
    "print()\n",
    "\n",
    "# 也可以对题目列表进行令牌化\n",
    "token_items = tokenizer(items)\n",
    "print(token_items)\n",
    "print()\n",
    "\n",
    "token_items = tokenizer(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128]) torch.Size([2, 128])\n",
      "torch.Size([2, 24, 128])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_dir = f\"{BASE_DIR}/examples/test_model/data/disenq\"\n",
    "t2v = DisenQModel(pretrained_dir)\n",
    "\n",
    "# 获得句表征和词表征\n",
    "t_vec, i_vec_k, i_vec_i = t2v(token_items)\n",
    "print(i_vec_k.shape, i_vec_i.shape)\n",
    "print(t_vec.shape)\n",
    "print()\n",
    "\n",
    "# 获得词表征\n",
    "t_vec = t2v.infer_tokens(token_items)\n",
    "\n",
    "# 获得句表征\n",
    "i_vec_k, i_vec_i = t2v.infer_vector(token_items)\n",
    "\n",
    "# 获得句表征\n",
    "i_vec_k = t2v.infer_vector(token_items, vector_type=\"k\")\n",
    "i_vec_i = t2v.infer_vector(token_items, vector_type=\"i\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a09bcfc86f5d80d5adfb774779878f28f4d48d5a6d6c0020bcfd8afaf909ec6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
